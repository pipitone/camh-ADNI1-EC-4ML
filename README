A project to prepare Hippocampal labels of ADNI images for machine learning
applications. 

This is branch is for the HC labels only, but follows the work done on the
master branch for EC

Registered images:  /projects/nikhil/EC_data/mni_registered_data
Segmentations: /scratch/jp/ADNI_EC/candidate_labels/

 - candidate_labels/ - a copy of all tarballs from nikhil
 - mni_candidates/ - candidate labels in mni space
 - mni_fused - fused labels in mni space

## Transforming candidate labels into mni space: 

  mkdir mni_candidates
  # loop over each tarball, resample, and tar
  for i in candidate_labels/*.tar; do 
    echo ./transform_candidates.sh $i mni_candidates/$(basename $i); 
  done | parallel -j24

  for i in mni_candidates/*_everything.tar; do
     mv ${i} ${i/_everything/}
  done
  
## Get bounding box for candidate labels

  We'll just the mask that Nikhil created by registering all of the Winterburn
  atlases to MNI space: `HC_atlas_mni_max.mnc`

## Convert labels to hdf5 (and crop)

  module load minc-tookit pyminc python python-extras SGE-extras

  mkdir mni_candidates_{l,r}
  for i in mni_candidates/*.tar; do 
    echo ./hdf_candidates.sh $i 1 mni_candidates_l/$(basename $i .tar)_l.h5; 
    echo ./hdf_candidates.sh $i 2 mni_candidates_r/$(basename $i .tar)_r.h5; 
  done > hdfify.jobs

  sge_submit_array hdfify.jobs -N HC_hdfify-

  ./hdfmerge.py mni_candidates_l/ candidate_labels_l.h5
  ./hdfmerge.py mni_candidates_r/ candidate_labels_r.h5


## Remove outlier labels, flatten, and drop mostly empty voxels

    ./remove_outliers.py candidate_labels_l.h5 cleaned_candidate_labels_l.h5
    ./remove_outliers.py candidate_labels_r.h5 cleaned_candidate_labels_r.h5

## Add classes and IDs 

    ./add-classes.py cleaned_candidate_labels_r.h5
    ./add-classes.py cleaned_candidate_labels_l.h5

## Divide into train, test and validation sets

    ./make-training-sets.py cleaned_candidate_labels_l.h5 training_l.h5
    ./make-training-sets.py cleaned_candidate_labels_r.h5 training_r.h5
